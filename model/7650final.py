# -*- coding: utf-8 -*-
"""7650final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gVJDd3RffB3PpTsUb9xEwwjhXs_4tb0I
"""

# Commented out IPython magic to ensure Python compatibility.
# # install GLiNER if not existed
# %%capture
# !pip install gliner

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch import LongTensor, FloatTensor
from torch.utils.data import Dataset, DataLoader, TensorDataset
from torch.nn.utils.rnn import pad_sequence
import numpy as np
import pandas as pd
from tqdm import tqdm
import json
import random
from collections import Counter
from gliner import GLiNER
from matplotlib import pyplot as plt

!wget 'https://raw.githubusercontent.com/SuperDim666/DistilledGliNER/main/model/data/data.json' -O data.json

def read_json_dataset(filename):
    with open(filename, 'r', encoding='utf-8') as file:
        data = json.load(file)
    sentences = []
    tags = []
    j = 0
    for entry in data:
        tokens = entry['tokenized_text']
        ner_tags = ['O'] * len(tokens)
        unavail_ner = False
        for ner in entry['ner']:
            start, end, label = ner
            if (not isinstance(label, str)):
                unavail_ner = True
                break
            for i in range(start, end + 1):
                if i == start:
                    # ner_tags[i] = 'B-' + label  # start lable: 'B-'
                    ner_tags[i] = label
                else:
                    # ner_tags[i] = 'I-' + label  # end lable 'I-'
                    ner_tags[i] = label  # end lable 'I-'

        if unavail_ner:
            continue
        # tokens.insert(0, '-START-')
        # tokens.append('-END-')
        # ner_tags.insert(0, '-START-')
        # ner_tags.append('-END-')
        sentences.append(tokens)
        tags.append(ner_tags)
    return sentences, tags

sentences_train, tags_train = read_json_dataset('data.json')
sentences_train = sentences_train[:1100]  # sentence in token
tags_train = tags_train[:1100] # tag in token
print(len(sentences_train))
print(sentences_train[0])
print(f'({len(sentences_train)},{len(sentences_train[0])})')
print(tags_train[0])

#Create mappings between tokens and indices.

tagCounts = Counter([w for l in tags_train for w in l])
tag_size = len(tagCounts)
print(f'tag_size: {tag_size}')
allTags = tagCounts.most_common(tag_size)
tagList = [tag for tag, _ in allTags]
# print(f'tagList: {tagList}')

wordCounts = Counter([w for l in sentences_train for w in l])
print(f'len(wordCounts): {len(wordCounts)}')

#Build dictionaries to map from words, characters to indices and vice versa.
#Save first two words in the vocabulary for padding and "UNK" token.
most_common_words = wordCounts.most_common(20000)
wordList = [word for word, _ in most_common_words]

merged_list = tagList[:]
merged_list.extend([x for x in wordList if x not in tagList])

word2id = {word: idx+2 for idx, word in enumerate(merged_list)}
word2id['UNK'] = 1
word2id['PAD'] = 0
vocab_size = len(word2id)
print(f'vocab_size: {vocab_size}')
id2word = {idx: word for word, idx in word2id.items()}

sentences_train_id = [[word2id.get(word, word2id['UNK']) for word in sentence] for sentence in sentences_train] # sentence in id
tags_train_id = [list(set([word2id.get(word, word2id['UNK']) for word in sentence])) for sentence in tags_train] # no repeated tags in id
for i in range(10):
  print(len(tags_train_id[i]))

print(f'list(word2id.items())[:10]: {list(word2id.items())[:10]}')
print(f'list(id2word.items())[:10]: {list(id2word.items())[:10]}')

print(f'sentences_train_id[0]: {sentences_train_id[0]}')

#Pad inputs to max sequence length (for batching)
# def prepare_input(X_list):
#     X_padded = pad_sequence([torch.as_tensor(l) for l in X_list], batch_first=True).type(LongTensor) # padding the sequences with 0
#     X_mask   = pad_sequence([torch.as_tensor([1.0] * len(l)) for l in X_list], batch_first=True).type(FloatTensor) # consisting of 0 and 1, 0 for padded positions, 1 for non-padded positions
#     return (X_padded, X_mask)

# (X_padded, X_mask) = prepare_input(sentences_train_id)
# # (tag_padded, tag_mask) = prepare_input(tags_train_id)
# print(f'X_padded[0,:20]: {X_padded[0,:20]}')
# print(f'X_padded.shape: {X_padded.shape}')
# # print(tag_padded.shape)

# tag_tensor = [torch.Tensor(list(tag)).type(LongTensor) for tag in tags_train_id]
# print(f'tag_tensor: {len(tag_tensor)}')
# print(f'tag_tensor[0]: {len(tag_tensor[0])}')

sentences_train_id_tensor = [torch.as_tensor(l) for l in sentences_train_id]
tags_train_id_tensor = [torch.as_tensor(l) for l in tags_train_id]
print(sentences_train_id_tensor[0])
print(tags_train_id_tensor[0])

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# real_label and label from teacher
teacher_model = GLiNER.from_pretrained("urchade/gliner_multi-v2.1")
teacher_model.to(device)

texts = [' '.join(sentence_train) for sentence_train in sentences_train]

labels = [[id2word[tag]  for tag in tag_train] for tag_train in tags_train_id]
print(labels[0])
real_label_list = []
real_label_scalar_list = []
teacher_label_list = []

for i in range(len(texts)):
  if i % 100 == 0:
    print("processed:", i)
  text = texts[i]
  label = labels[i]
  entities = teacher_model.predict_entities(text, label, threshold=0.4)
  teacher_label = np.zeros((len(sentences_train[i]),len(label)))
  real_label = np.zeros((len(sentences_train[i]), len(label)))
  entity_idx = 0
  cnt = 0
  real_label_scalar = []
  for j in range(len(sentences_train[i])):
    idx = label.index(tags_train[i][j])
    real_label_scalar.append(idx)
    real_label[j][idx] = 1

    teacher_label[j][idx] = 1
    if entity_idx < len(entities) and idx != 0:
      cnt += 1
      teacher_label[j][idx] = entities[entity_idx]['score']
      other_score = (1 - entities[entity_idx]['score']) / (len(label) - 1)
      # if j == 5:
        # print(entities[entity_idx]['score'])
        # print(other_score)
      for k in range(len(label)):
        if k == idx:
          continue
        else:
          teacher_label[j][k] = other_score
      if len(entities[entity_idx]['text'].split(' ')) == cnt:
        entity_idx += 1
        cnt = 0
  real_label_scalar_list.append(np.array(real_label_scalar))
  real_label_list.append(torch.from_numpy(real_label))
  teacher_label_list.append(torch.from_numpy(teacher_label))


print(real_label_list[0][5,:])
print(teacher_label_list[0][5,:])
print(entities)

class StudentLSTM(nn.Module):
    def __init__(self, vocab_size, tag_vocab_size, emb_dim, hidden_dim, device):
        super(StudentLSTM, self).__init__()
        self.word_embeddings = nn.Embedding(vocab_size, emb_dim)
        # self.tag_embeddings = nn.Embedding(tag_vocab_size, emb_dim)

        self.sentence_lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)
        self.tag_fc = nn.Linear(emb_dim, hidden_dim)

        self.device = device

    def forward(self, sentence_input, tag_inputs):
        sentence_input = sentence_input.to(self.device)
        tag_inputs = tag_inputs.to(self.device)
        sentence_emb = self.word_embeddings(sentence_input)
        # print(f'sentence_emb.shape [batch_size, sentence_size, emb_size]: {sentence_emb.shape}')
        sentence_outputs, (_ , _) = self.sentence_lstm(sentence_emb)
        # sentence_features = sentence_hidden[-1]

        tag_emb = self.word_embeddings(tag_inputs)

        tag_emb = self.tag_fc(tag_emb)

        # tag_emb = tag_emb.expand(sentence_outputs.shape[0], -1, -1)  # [batch_size, tag_size, emb_size]
        # print(f'tag_emb.shape [batch_size, tag_size, emb_size]: {tag_emb.shape}')

        # print(sentence_outputs.shape)
        # print(tag_emb.shape)


        result = torch.matmul(sentence_outputs, tag_emb.transpose(0, 1))  # [batch_size, seq_len, tag_size]

        # result = result.transpose(1, 2)  # [batch_size, tag_size, seq_len]

        # print(f'result.shape [batch_size, tag_size, seq_len]: {result.shape}')

        return result  # Tensor of scores of all labels

# Student model
emb_dim = 300
hidden_dim = emb_dim
student_model = StudentLSTM(vocab_size, tag_size, emb_dim, hidden_dim, device)
student_model.to(device)

batch_size = 1

class DistilledDataset(Dataset):
    def __init__(self, texts, padded_sequences):
        self.texts = texts
        self.padded_sequences = padded_sequences

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        padded_seq = self.padded_sequences[idx]
        return text, padded_seq

def distilled_collate_fn(batch):
    texts      = [item[0] for item in batch]
    padded_seq = [item[1] for item in batch]
    return texts, torch.stack(padded_seq)

# print(f'sentences_train.shape: ({len(sentences_train)},{len(sentences_train[0])})')
# print(f'X_padded.shape: ({X_padded.shape})')
# train_loader = DataLoader(DistilledDataset(sentences_train, X_padded), batch_size=batch_size, shuffle=True, collate_fn=distilled_collate_fn)

def distillation_loss(y_student, y_teacher, real_label, T=2.0):
    alpha = 0.5
    soft_loss = F.binary_cross_entropy_with_logits(y_student, y_teacher, reduction='sum')
    hard_loss = F.binary_cross_entropy_with_logits(y_student, real_label, reduction='sum')
    return alpha * soft_loss + (1-alpha) * hard_loss

def normal_loss(y_student, real_label):
    loss = F.binary_cross_entropy_with_logits(y_student, real_label, reduction='sum')
    return loss

def predict_tag_test_dataset(model):
  correct_accuracy = 0
  total_accuracy = 0
  correct_positive = 0
  total_positive = 0
  predicted_total_positive = 0
  for idx, sentence_train_id_tensor in enumerate(sentences_train_id_tensor[1000:1100]):
    model.eval()
    i = idx + 1000
    with torch.no_grad():
      sentence_train_id_tensor = sentence_train_id_tensor.to(device)
      tag_train_id_tensor = tags_train_id_tensor[i].to(device)
      student_logits = student_model(sentence_train_id_tensor, tag_train_id_tensor)
      student_logits = student_logits.cpu().numpy()
      student_logits = np.argmax(student_logits, axis=1)
      correct_accuracy += np.sum(student_logits == real_label_scalar_list[i])
      total_accuracy += len(student_logits)
      correct_positive += np.sum((student_logits == real_label_scalar_list[i]) & (real_label_scalar_list[i]!=0))
      total_positive += np.sum(real_label_scalar_list[i]!=0)
      predicted_total_positive += np.sum(student_logits!=0)

  accuracy = correct_accuracy / total_accuracy
  recall = min(correct_positive / total_positive,1)
  precision = min(total_positive / predicted_total_positive,1)
  f1_score = 2 * (precision * recall) / (precision + recall)
  return accuracy, precision, recall, f1_score


def predict_tag_train_dataset(model):
  correct_accuracy = 0
  total_accuracy = 0
  correct_positive = 0
  total_positive = 0
  predicted_total_positive = 0
  for idx, sentence_train_id_tensor in enumerate(sentences_train_id_tensor[:1000]):
    model.eval()
    i = idx
    with torch.no_grad():
      sentence_train_id_tensor = sentence_train_id_tensor.to(device)
      tag_train_id_tensor = tags_train_id_tensor[i].to(device)
      student_logits = student_model(sentence_train_id_tensor, tag_train_id_tensor)
      student_logits = student_logits.cpu().numpy()
      student_logits = np.argmax(student_logits, axis=1)
      correct_accuracy += np.sum(student_logits == real_label_scalar_list[i])
      total_accuracy += len(student_logits)
      correct_positive += np.sum((student_logits == real_label_scalar_list[i]) & (real_label_scalar_list[i]!=0))
      total_positive += np.sum(real_label_scalar_list[i]!=0)
      predicted_total_positive += np.sum(student_logits!=0)

  accuracy = correct_accuracy / total_accuracy
  recall = min(correct_positive / total_positive,1)
  precision = min(total_positive / predicted_total_positive,1)
  f1_score = 2 * (precision * recall) / (precision + recall)
  return accuracy, precision, recall, f1_score

def init_weights(m):
    if isinstance(m, torch.nn.Linear):
        torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')
        if m.bias is not None:
            m.bias.data.fill_(0.0)
    elif isinstance(m, torch.nn.Embedding):
        torch.nn.init.uniform_(m.weight, -1.0, 1.0)

student_model.apply(init_weights)

optimizer = optim.Adam(student_model.parameters(), lr=0.001)
epochs = 10

distilled_accuracy_list = []
distilled_precision_list = []
distilled_recall_list = []
distilled_f1_score_list = []
distilled_loss_list = []
distilled_recall_train_list = []
for epoch in range(epochs):
    student_model.train()
    total_loss = 0

    for i, sentence_train_id_tensor in enumerate(sentences_train_id_tensor[:1000]):
        sentence_train_id_tensor = sentence_train_id_tensor.to(device)
        tag_train_id_tensor = tags_train_id_tensor[i].to(device)

        # Predict from Student model
        student_logits = student_model(sentence_train_id_tensor, tag_train_id_tensor)
        # print(student_logits.shape)
        # print(teacher_label_list[i].shape)
        # print(real_label_list[i].shape)

        loss = distillation_loss(student_logits, teacher_label_list[i].to(device),real_label_list[i].to(device))

        # Backpropagation and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    accuracy, precision, recall, f1_score = predict_tag_test_dataset(student_model)
    accuracy_train, precision_train, recall_train, f1_score_train = predict_tag_train_dataset(student_model)
    print(f"Epoch {epoch + 1}, Loss: {total_loss / len(sentences_train_id_tensor)} Accuracy: {accuracy}, Precision: {precision}, Recall:{recall}, Recall_train: {recall}, F1_score:{f1_score}")
    distilled_recall_train_list.append(recall_train)
    distilled_accuracy_list.append(accuracy)
    distilled_precision_list.append(precision)
    distilled_recall_list.append(recall)
    distilled_f1_score_list.append(f1_score)
    distilled_loss_list.append(total_loss / len(sentences_train_id_tensor))

student_model.apply(init_weights)


optimizer = optim.Adam(student_model.parameters(), lr=0.001)
epochs = 10

accuracy_list = []
precision_list = []
recall_list = []
f1_score_list = []
loss_list = []
recall_train_list = []
for epoch in range(epochs):
    student_model.train()
    total_loss = 0

    for i, sentence_train_id_tensor in enumerate(sentences_train_id_tensor):
        sentence_train_id_tensor = sentence_train_id_tensor.to(device)
        tag_train_id_tensor = tags_train_id_tensor[i].to(device)

        # Predict from Student model
        student_logits = student_model(sentence_train_id_tensor, tag_train_id_tensor)
        # print(student_logits.shape)
        # print(teacher_label_list[i].shape)
        # print(real_label_list[i].shape)

        loss = normal_loss(student_logits, real_label_list[i].to(device))

        # Backpropagation and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    accuracy, precision, recall, f1_score = predict_tag_test_dataset(student_model)
    accuracy_train, precision_train, recall_train, f1_score_train = predict_tag_train_dataset(student_model)
    print(f"Epoch {epoch + 1}, Loss: {total_loss / len(sentences_train_id_tensor)} Accuracy: {accuracy}, Precision: {precision}, Recall:{recall}, Recall_train:{recall_train}, F1_score:{f1_score}")

    recall_train_list.append(recall_train)
    accuracy_list.append(accuracy)
    precision_list.append(precision)
    recall_list.append(recall)
    f1_score_list.append(f1_score)
    loss_list.append(total_loss / len(sentences_train_id_tensor))

plt.plot([i for i in range(epochs)], distilled_loss_list, label='Normal Loss')
plt.plot([i for i in range(epochs)], loss_list, label='Distilled Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Comparison on Loss')
plt.legend()
plt.show()

plt.plot([i for i in range(epochs)], distilled_accuracy_list, label='Normal Accuracy')
plt.plot([i for i in range(epochs)], accuracy_list, label='Distilled Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Comparison on Accuracy')
plt.legend()
plt.show()

plt.plot([i for i in range(epochs)], distilled_precision_list, label='Normal Precision')
plt.plot([i for i in range(epochs)], precision_list, label='Distilled Precision')
plt.xlabel('Epochs')
plt.ylabel('Precision')
plt.title('Comparison on Precision')
plt.legend()
plt.show()

plt.plot([i for i in range(epochs)], distilled_recall_list, label='Normal Recall')
plt.plot([i for i in range(epochs)], recall_list, label='Distilled Recall')
plt.xlabel('Epochs')
plt.ylabel('Recall')
plt.title('Comparison on Recall')
plt.legend()
plt.show()

plt.plot([i for i in range(epochs)], distilled_f1_score_list, label='Normal F1_score')
plt.plot([i for i in range(epochs)], f1_score_list, label='Distilled F1_score')
plt.xlabel('Epochs')
plt.ylabel('F1_score')
plt.title('Comparison on F1_score')
plt.legend()
plt.show()

plt.plot([i for i in range(epochs)], distilled_recall_train_list, label='Normal Recall on Training Set')
plt.plot([i for i in range(epochs)], recall_train_list, label='Distilled Recall on Training Set')
plt.xlabel('Epochs')
plt.ylabel('Recall')
plt.title('Comparison on Recall of Training Set')
plt.legend()
plt.show()